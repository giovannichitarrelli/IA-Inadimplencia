 # V7 - Eliminando base insights e passando contexto via endpoints e palavras-chave 
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
import httpx
import pandas as pd
from PIL import Image
import pyodbc
import re
import time
from dotenv import load_dotenv
import os

load_dotenv()

api_key = os.getenv("API_KEY")
 
st.set_page_config(page_title="An√°lise de Inadimpl√™ncia", page_icon="üíº")

if "app_initialized" not in st.session_state:
    st.session_state.app_initialized = False

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
 
def get_llm_client():
    return ChatOpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com",
        model="deepseek-chat",
        http_client=httpx.Client(verify=False)
    )

# Conex√£o com o banco de dados
def connect_to_db():
    server = os.getenv('SERVER')
    database = os.getenv('DATABASE')
    username = os.getenv('USERNAME')
    password = os.getenv('PASSWORD')
    table = os.getenv('TABLE')
    try:
        connection_string = (
            f"DRIVER={{ODBC Driver 18 for SQL Server}};"
            f"SERVER={server};"
            f"DATABASE={database};"
            f"UID={username};"
            f"PWD={password};"
            f"Encrypt=yes;"
            f"TrustServerCertificate=no;"
            f"Connection Timeout=30;"
        )
        conn = pyodbc.connect(connection_string)
        return conn, table
    except pyodbc.Error as e:
        st.error(f"Erro ao conectar ao banco de dados: {str(e)}")
        return None, None

# Fun√ß√£o para obter colunas da tabela
def get_table_columns(conn, table):
    try:
        cursor = conn.cursor()
        cursor.execute(f"SELECT TOP 1 * FROM {table}")
        columns = [desc[0] for desc in cursor.description]
        cursor.close()
        return columns
    except pyodbc.Error as e:
        st.error(f"Erro ao obter colunas da tabela: {str(e)}")
        return []

def main():
    st.title("üí¨ Chatbot Inadimplinha")
    st.caption("üöÄ Chatbot Inadimplinha desenvolvido por Grupo de Inadimpl√™ncia EY")
    
    conn, table = connect_to_db()
    if conn is None:
        st.stop()
    
    available_columns = get_table_columns(conn, table)
    if not available_columns:
        st.error("N√£o foi poss√≠vel recuperar as colunas da tabela 'inad_consolidado'.")
        conn.close()
        st.stop()
    
    llm = get_llm_client()

    # Definir o template de prompt
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", (
            "Voc√™ √© um especialista em an√°lise de inadimpl√™ncia no Brasil. "
            "Responda a pergunta do usu√°rio com base nos dados da tabela '{table}' "
            "sem passar detalhes t√©cnicos e informa√ß√µes sobre as tabelas que est√£o sendo usadas. "
            "Sempre forne√ßa valores totais reais (em reais, R$) calculados a partir dos dados, "
            "N√£o forne√ßa detalhes como nome das colunas ou como deveria ser feita a consulta sql, "
            "Insira informa√ß√µes adicionais relevantes sobre o tema quando apropriado. "
            "As colunas dispon√≠veis s√£o: {available_columns}. "
        )),
        ("human", "{input}")
    ])


    # Criar a cadeia de execu√ß√£o
    chain = prompt_template | llm

    # Inicializar o hist√≥rico de mensagens
    if "chat_history_store" not in st.session_state:
        st.session_state.chat_history_store = InMemoryChatMessageHistory()

    # Envolver a cadeia com hist√≥rico de mensagens
    conversation = RunnableWithMessageHistory(
        runnable=chain,
        get_session_history=lambda: st.session_state.chat_history_store,
        input_messages_key="input",
        history_messages_key="chat_history"
    )
    
    # Adicionar mensagem inicial apenas uma vez
    if not st.session_state.app_initialized and not st.session_state.chat_history:
        initial_message = "Como posso te ajudar hoje?"
        st.session_state.chat_history.append({"role": "assistant", "content": initial_message})
        st.session_state.chat_history_store.add_ai_message(initial_message)
        st.session_state.app_initialized = True
    
    # Exibir hist√≥rico de chat para o usu√°rio
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    if prompt := st.chat_input("Fa√ßa uma pergunta sobre a inadimpl√™ncia"):
        # Adicionar a pergunta do usu√°rio √† interface de chat
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Adicionar √† exibi√ß√£o do hist√≥rico
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        # Processar a resposta
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            
            try:
                with st.spinner(""):
                    # Executar a consulta com contexto
                    response = conversation.invoke(
                        {"input": prompt, "table": table, "available_columns": available_columns},
                        config={"configurable": {"session_id": "default"}}
                    )
                    response_stream = response.content
                    
                    # Simulando streaming para melhor UX
                    full_response = ""
                    for i in range(len(response_stream)):
                        full_response = response_stream[:i+1]
                        message_placeholder.markdown(full_response + "‚ñå")
                        time.sleep(0.01)
                    
                    # Verificar se h√° uma consulta SQL na resposta
                    sql_match = re.search(r"```sql\n(.*?)\n```", full_response, re.DOTALL)
                    if sql_match:
                        query = sql_match.group(1)
                        # Corrigir a posi√ß√£o do TOP se necess√°rio
                        if "TOP" in query and "ORDER BY" in query and query.index("TOP") > query.index("ORDER BY"):
                            top_match = re.search(r"TOP\s+(\d+)", query)
                            top_number = top_match.group(1) if top_match else "1"
                            query = re.sub(r"TOP\s+\d+\s*;", "", query)
                            query = query.replace("SELECT", f"SELECT TOP {top_number}", 1)
                        
                        # Executar a consulta no banco
                        df = pd.read_sql(query, conn)
                        
                        # Substituir SQL com os resultados formatados
                        formatted_response = full_response.replace(sql_match.group(0), df.to_string(index=False))
                        message_placeholder.markdown(formatted_response)
                        final_response = formatted_response
                    else:
                        # Se n√£o houver SQL, usar a resposta direta
                        message_placeholder.markdown(full_response)
                        final_response = full_response
                    
                    # Adicionar √† exibi√ß√£o do hist√≥rico ap√≥s a resposta estar completa
                    st.session_state.chat_history.append({"role": "assistant", "content": final_response})
                
            except pyodbc.Error as e:
                error_message = f"Erro ao executar a consulta no banco: {str(e)}"
                message_placeholder.markdown(error_message)
                st.session_state.chat_history.append({"role": "assistant", "content": error_message})
                st.session_state.chat_history_store.add_ai_message(error_message)
            except Exception as e:
                error_message = f"Erro no processamento: {str(e)}"
                message_placeholder.markdown(error_message)
                st.session_state.chat_history.append({"role": "assistant", "content": error_message})
                st.session_state.chat_history_store.add_ai_message(error_message)

    # Sidebar
    with st.sidebar:
        ey_logo = Image.open(r"EY_Logo.png")
        ey_logo_resized = ey_logo.resize((100, 100))   
        st.sidebar.image(ey_logo_resized)
        st.sidebar.header("EY Academy | Inadimpl√™ncia")

        st.sidebar.subheader("üîç Sugest√µes de An√°lise")
        st.sidebar.write("‚û°Ô∏è Qual estado com maior inadimpl√™ncia e quais os valores devidos?")
        st.sidebar.write("‚û°Ô∏è Qual cliente apresenta o maior n√∫mero de opera√ß√µes?")
        st.sidebar.write("‚û°Ô∏è Em qual modalidade existe maior inadimpl√™ncia?")
        st.sidebar.write("‚û°Ô∏è Compare a inadimpl√™ncia entre PF e PJ")
        st.sidebar.write("‚û°Ô∏è Qual ocupa√ß√£o entre PF possui maior inadimpl√™ncia?")
        st.sidebar.write("‚û°Ô∏è Qual o principal porte de cliente com inadimpl√™ncia entre PF?")
        st.sidebar.write("‚û°Ô∏è Qual se√ß√£o CNAE possui a maior inadimplencia?")
        st.sidebar.write("‚û°Ô∏è Qual estado tem o maior valor m√©dio de opera√ß√µes a vencer em at√© 90 dias?")
        
        # Bot√£o para limpar hist√≥rico de conversa
        if st.button("Limpar Conversa"):
            st.session_state.chat_history_store = InMemoryChatMessageHistory()
            st.session_state.chat_history = []
            st.session_state.app_initialized = False
            st.rerun()
   
    conn.close()

if __name__ == "__main__":
    main()
    
 