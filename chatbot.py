
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
import httpx
import pandas as pd
from PIL import Image
import time
import os
from dotenv import load_dotenv
from sqlalchemy import create_engine
from insights import generate_advanced_insights
from urllib.parse import quote_plus
 
load_dotenv()

api_key = os.getenv("API_KEY")
st.set_page_config(page_title="An√°lise de Inadimpl√™ncia", page_icon="")

if "app_initialized" not in st.session_state:
    st.session_state.app_initialized = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

def get_llm_client():
    return ChatOpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com",
        model="deepseek-chat",
        http_client=httpx.Client(verify=False)
    )

def connect_to_db():
    try:
        # print("Tentando conectar ao banco de dados PostgreSQL no GCP...")
        # Dados de conex√£o
        host = os.getenv("SERVER")
        database = os.getenv("DATABASE")
        username = os.getenv("USERNAME")
        password = os.getenv("PASSWORD")
        port = os.getenv("PORT")

        # Validar os valores
        if not all([host, database, username, password, port]):
            raise ValueError("Uma ou mais vari√°veis de ambiente n√£o est√£o definidas no .env")

        # Codificar a senha para lidar com caracteres especiais
        encoded_password = quote_plus(password)

        # String de conex√£o com senha codificada
        connection_string = f"postgresql://{username}:{encoded_password}@{host}:{port}/{database}"
        # print(f"String de conex√£o: {connection_string}")  # Para depura√ß√£o, remova em produ√ß√£o

        # Criar engine do SQLAlchemy
        engine = create_engine(connection_string)

        # Testar a conex√£o
        with engine.connect() as connection:
            print("Conex√£o com o banco de dados estabelecida com sucesso!")
        
        return engine

    except Exception as e:
        print(f"Erro ao conectar ao banco de dados: {e}")
        return None  

def load_data(engine):
    try:
        table = "table_agg_inad_consolidado"
        query = f"SELECT * FROM {table}"
        df = pd.read_sql(query, engine)
        return df
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")
        return None

def main():
    st.title("Chatbot Inadimplinha")
    st.caption("Chatbot Inadimplinha desenvolvido por Grupo de Inadimpl√™ncia EY")

    engine = connect_to_db()
    if engine is None:
        st.stop()

    if "insights" not in st.session_state:
        df = load_data(engine)
        if df is None:
            engine.dispose()  # Fechar o engine em caso de erro
            st.stop()
        st.session_state.insights = generate_advanced_insights(df)

    llm = get_llm_client()
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", (
            "Voc√™ √© um especialista em an√°lise de inadimpl√™ncia no Brasil. "
            "Use os insights pr√©-calculados abaixo para responder √†s perguntas do usu√°rio de forma clara e objetiva. "
            "N√£o gere consultas SQL ou acesse dados diretamente; baseie-se apenas nos insights fornecidos. "
            "Se a pergunta n√£o puder ser respondida com os insights dispon√≠veis, informe isso ao usu√°rio. "
            "Insights dispon√≠veis:\n\n{insights}"
        )),
        ("human", "{input}")
    ])

    # Criar a cadeia de execu√ß√£o
    chain = prompt_template | llm

    # Inicializar o hist√≥rico de mensagens
    if "chat_history_store" not in st.session_state:
        st.session_state.chat_history_store = InMemoryChatMessageHistory()

    # Envolver a cadeia com hist√≥rico de mensagens
    conversation = RunnableWithMessageHistory(
        runnable=chain,
        get_session_history=lambda: st.session_state.chat_history_store,
        input_messages_key="input",
        history_messages_key="chat_history"
    )

    # Adicionar mensagem inicial apenas uma vez
    if not st.session_state.app_initialized and not st.session_state.chat_history:
        initial_message = "Como posso te ajudar hoje?"
        st.session_state.chat_history.append({"role": "assistant", "content": initial_message})
        st.session_state.chat_history_store.add_ai_message(initial_message)
        st.session_state.app_initialized = True

    # Exibir hist√≥rico de chat para o usu√°rio
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Fa√ßa uma pergunta sobre a inadimpl√™ncia"):
        # Adicionar a pergunta do usu√°rio √† interface de chat
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Adicionar √† exibi√ß√£o do hist√≥rico
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        # Processar a resposta
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            
            try:
                with st.spinner(""):
                    # Executar a consulta com os insights pr√©-definidos
                    response = conversation.invoke(
                        {"input": prompt, "insights": st.session_state.insights},
                        config={"configurable": {"session_id": "default"}}
                    )
                    response_stream = response.content
                    
                    # Simulando streaming para melhor UX
                    full_response = ""
                    for i in range(len(response_stream)):
                        full_response = response_stream[:i+1]
                        message_placeholder.markdown(full_response + "‚ñå")
                        time.sleep(0.01)
                    message_placeholder.markdown(full_response)
                    
                    # Adicionar √† exibi√ß√£o do hist√≥rico
                    st.session_state.chat_history.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                error_message = f"Erro no processamento: {str(e)}"
                message_placeholder.markdown(error_message)
                st.session_state.chat_history.append({"role": "assistant", "content": error_message})
                st.session_state.chat_history_store.add_ai_message(error_message)

    with st.sidebar:
        ey_logo = Image.open(r"EY_Logo.png")
        ey_logo_resized = ey_logo.resize((100, 100))   
        st.sidebar.image(ey_logo_resized)
        st.sidebar.header("EY Academy | Inadimpl√™ncia")

        st.sidebar.subheader("üîç Sugest√µes de An√°lise")
        st.sidebar.write("‚û°Ô∏è Qual estado com maior inadimpl√™ncia e quais os valores devidos?")
        st.sidebar.write("‚û°Ô∏è Qual tipo de cliente apresenta o maior n√∫mero de opera√ß√µes?")
        st.sidebar.write("‚û°Ô∏è Em qual modalidade existe maior inadimpl√™ncia?")
        st.sidebar.write("‚û°Ô∏è Compare a inadimpl√™ncia entre PF e PJ")
        st.sidebar.write("‚û°Ô∏è Qual ocupa√ß√£o entre PF possui maior inadimpl√™ncia?")
        st.sidebar.write("‚û°Ô∏è Qual o principal porte de cliente com inadimpl√™ncia entre PF?")
        
        # Bot√£o para limpar hist√≥rico de conversa
        if st.button("Limpar Conversa"):
            st.session_state.chat_history_store = InMemoryChatMessageHistory()
            st.session_state.chat_history = []
            st.session_state.app_initialized = False
            if "insights" in st.session_state:
                del st.session_state.insights  # Recarregar insights na pr√≥xima execu√ß√£o
            st.rerun()

    engine.dispose()  # Fechar o engine ao final da execu√ß√£o

if __name__ == "__main__":
    main()